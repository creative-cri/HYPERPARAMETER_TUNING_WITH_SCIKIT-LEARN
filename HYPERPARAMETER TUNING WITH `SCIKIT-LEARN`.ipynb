{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1032ac5",
   "metadata": {},
   "source": [
    "# HYPERPARAMETER TUNING WITH `SCIKIT-LEARN`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dabef5",
   "metadata": {},
   "source": [
    "# 1. GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ea5506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LogisticRegression(max_iter=1000, solver='liblinear'),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Load the data set\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target)\n",
    "\n",
    "# These are the hyperparameters that we will test.\n",
    "# We'll try both 'l1' and 'l2' regularization.\n",
    "# C is the inverse of regularization strength. Smaller C will result in stronger regularization.\n",
    "parameters = {'penalty': ['l1', 'l2'], 'C': [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "# The logistic regression model\n",
    "# The 'liblinear' solver is compatible with both 'l1' and 'l1' penalties.\n",
    "# Setting max_iter to 1000 ensures that the solver will converge for this particular data set.\n",
    "lr = LogisticRegression(solver='liblinear', max_iter=1000)\n",
    "\n",
    "# Create a GridSearchCV model\n",
    "# This will train the model 'lr' with each possible combination of hyperparameters in 'parameters'\n",
    "clf = GridSearchCV(lr,parameters)\n",
    "\n",
    "# Fit the GridSearchCV model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f9b43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1000, max_iter=1000, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Print the hyperparameters that performed the best.\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3f3e40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 0.1, 'penalty': 'l1'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 1, 'penalty': 'l1'}, {'C': 1, 'penalty': 'l2'}, {'C': 10, 'penalty': 'l1'}, {'C': 10, 'penalty': 'l2'}, {'C': 100, 'penalty': 'l1'}, {'C': 100, 'penalty': 'l2'}, {'C': 1000, 'penalty': 'l1'}, {'C': 1000, 'penalty': 'l2'}]\n"
     ]
    }
   ],
   "source": [
    "print(clf.cv_results_['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b84ba1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93192886 0.93896033 0.94834473 0.94599179 0.9553762  0.95534884\n",
      " 0.9553762  0.96005472 0.95772914 0.96010944]\n"
     ]
    }
   ],
   "source": [
    "# Print the score of the model with each combination of hyperparameters.\n",
    "print(clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc49b0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Score          \n",
      "penalty        l1        l2\n",
      "C                          \n",
      "0.1      0.931929  0.938960\n",
      "1.0      0.948345  0.945992\n",
      "10.0     0.955376  0.955349\n",
      "100.0    0.955376  0.960055\n",
      "1000.0   0.957729  0.960109\n"
     ]
    }
   ],
   "source": [
    "# This Pandas DataFrame tabulates hyperparameter values and the associated scores\n",
    "import pandas as pd\n",
    " \n",
    "df = pd.concat([pd.DataFrame(clf.cv_results_['params']), pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['Score'])] ,axis=1)\n",
    " \n",
    "cv_table = df.pivot(index='C', columns='penalty')\n",
    " \n",
    "print(cv_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "545ce0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "#Compute and print the accuracy of the model on test data\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11e988b",
   "metadata": {},
   "source": [
    "# 2. RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4fb0f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Load the data set\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40010d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the hyperparameters that we will test.\n",
    "# We'll try both 'l1' and 'l2' regularization.\n",
    "# C is the inverse of regularization strength. Smaller C will result in stronger regularization.\n",
    "distributions = {'penalty': ['l1', 'l2'], 'C': uniform(loc=0, scale=100)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f4b1093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The logistic regression model\n",
    "lr = LogisticRegression(solver = 'liblinear', max_iter = 1000)\n",
    "\n",
    "# Create a RandomizedSearchCV model\n",
    "clf = RandomizedSearchCV(lr, distributions, n_iter=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23affd3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=LogisticRegression(max_iter=1000,\n",
       "                                                solver='liblinear'),\n",
       "                   n_iter=8,\n",
       "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001B021B3B6D0>,\n",
       "                                        'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomizedSearchCV model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18adda95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=43.03655869605423, max_iter=1000, penalty='l1',\n",
      "                   solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "# Show which hyperparameters performed the best\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5339f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 93.940849899094, 'penalty': 'l2'}, {'C': 64.3046686743434, 'penalty': 'l2'}, {'C': 10.485023129974635, 'penalty': 'l2'}, {'C': 78.46217201189137, 'penalty': 'l2'}, {'C': 43.03655869605423, 'penalty': 'l1'}, {'C': 39.6588441504642, 'penalty': 'l1'}, {'C': 54.70926946780115, 'penalty': 'l1'}, {'C': 75.78108256224327, 'penalty': 'l2'}]\n",
      "[0.9553762  0.9553762  0.96005472 0.96008208 0.97181943 0.97181943\n",
      " 0.96946648 0.95772914]\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy of the model on validation data\n",
    "print(clf.cv_results_['params'])\n",
    "print(clf.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e3c659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           C penalty  Accuracy\n",
      "4  43.036559      l1  0.971819\n",
      "5  39.658844      l1  0.971819\n",
      "6  54.709269      l1  0.969466\n",
      "3  78.462172      l2  0.960082\n",
      "2  10.485023      l2  0.960055\n",
      "7  75.781083      l2  0.957729\n",
      "0  93.940850      l2  0.955376\n",
      "1  64.304669      l2  0.955376\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    " \n",
    "df = pd.concat([pd.DataFrame(clf.cv_results_['params']), pd.DataFrame(clf.cv_results_['mean_test_score'], columns=['Accuracy'])] ,axis=1)\n",
    " \n",
    "print(df.sort_values('Accuracy', ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8b05c28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.958041958041958\n"
     ]
    }
   ],
   "source": [
    "# Compute and print the accuracy of the model on test data\n",
    "acc = clf.score(X_test, y_test)\n",
    "print(acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
